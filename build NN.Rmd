---
title: "build NN"
author: "Devraj Kori"
date: "12/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(e1071)
library(caret)
library(foreach)
library(doParallel)
library(tcltk)
library(doSNOW)
library(keras)
library(ROCR)
```

```{r load_data,echo=FALSE}
load("for modeling.RData")
#to avoid adding too much dimensionality, only keep percent variables for race and lunch
# dropped_nas<-dropped_nas%>%
#   select(-c(american_indian,asian,hisp,black,white,pacific_islander,multi_racial,ln_stud_teacher_ratio))%>%
#   #make closed_any a factor since SVM is a categorical classifier
#   mutate(closed_any=factor(closed_any))%>%
#   filter(!is.na(urban_locale_type))

with_imputations<-with_imputations%>%
  #select(-c(american_indian,asian,hisp,black,white,pacific_islander,multi_racial,ln_stud_teacher_ratio))%>%
  #make closed_any a factor since SVM is a categorical classifier
  mutate(closed_any=factor(closed_any))%>%
  filter(!is.na(urban_locale_type))%>%
  filter(state!="PR")%>%
  select(-c("state","cd"))

```


```{r prep_data}
#make character variables into factors
for(var in names(with_imputations)){
  temp_vector<-with_imputations[,var]
  if(is.character(temp_vector[[1]])){
    temp_vector[[1]]<-factor(temp_vector[[1]])
  }
  with_imputations[,var]<-temp_vector
}
#create a function that turns the factor variables into dummies
create_dummies<-function(df){
  cols<-colnames(df)
  for(i in 1:length(cols)){
    col<-cols[i]
    temp_frame<-df[,i]
    #test if the column is a character
    if(is.factor(temp_frame[[col]])){
      #create a model matrix of binaries for each category of the character variable
      names(temp_frame)<-"binary"
      temp_frame2<-data.frame(model.matrix(~binary,data=temp_frame))[-1]
      colnames(temp_frame2)<-gsub("binary",col,colnames(temp_frame2))
    }else{
      #if not character, just keep it the same
      temp_frame2<-temp_frame
    }
    if(i==1){
      #we don't want to replace the first column, quick way to skip it
      result_frame<-temp_frame2
    }else{
      result_frame<-cbind(result_frame,temp_frame2)
    }
  }
  result_frame
}

#apply create_dummies function to everything but closed_any
with_imputations_wide<-create_dummies(with_imputations)

set.seed(200)
#split train and test, create matrices
traini<-sample(1:nrow(with_imputations_wide),size=nrow(with_imputations_wide)*.5)
train<-with_imputations_wide[traini,]
test<-with_imputations_wide[-traini,]

#create x and y matrices for train and test sets
xtrain<-train%>%select(-c("closed_any1"))%>%as.matrix()
xtest<-test%>%select(-c("closed_any1"))%>%as.matrix()

ytrain<-train[,"closed_any1"]%>%as.matrix()
ytest<-test[,"closed_any1"]%>%as.matrix()


```

```{r base_model}
#create a base model with 3 hidden layers
base_model=keras_model_sequential()
l1=1e-2

base_model%>%
  layer_dense(units=32,activation="relu",kernel_regularizer=regularizer_l1(l1),
              input_shape=ncol(xtrain))%>%
  #layer_dense(units=32,activation="relu",kernel_regularizer=regularizer_l1(l1))%>%
  #layer_dense(units=32,activation="tanh",kernel_regularizer=regularizer_l1(l1))%>%

  layer_dense(units=32,activation="relu",kernel_regularizer=regularizer_l1(l1))%>%
  layer_dense(units=1,activation="sigmoid",kernel_regularizer=regularizer_l1(l1))
summary(base_model)


```


```{r train_base_model}
#compile base model, binary_crossentropy is appropriate for classification task
base_model%>%compile(
  loss='binary_crossentropy',
  optimizer=optimizer_adam(),
  metrics=c('mae')
)
history = base_model%>%fit(xtrain,ytrain,
                       epochs=125,
                       batch_size=64,
                       validation_split=0.2,
                       #define class_weights to account for rarity of school closures
                       class_weights=c("0"=1,"1"=23),
                       shuffle=T)
```

```{r run_base_model_on_validation}
preds<-predict(base_model,batch_size = 64, x=xtest)

prediction_matrix<-table(preds,ytest)%>%as.data.frame
ft_auc=prediction(preds,ytest)%>%
  performance("auc")%>%.@y.values%>%.[[1]]

prediction(preds,ytest)%>%
  performance(measure="tpr",x.measure="fpr")%>%plot()

base_density<-prediction_matrix%>%
  uncount(Freq)%>%
  mutate(preds=as.numeric(paste0(preds)))%>%
  ggplot(aes(x=preds,colour=ytest,fill=ytest))+
  geom_density(alpha=.5)
base_density
#create a test confusion matrix
table(ifelse(as.numeric(paste0(preds))>.05,1,0),
      ytest)

summary(base_model)
summary(base_model2)
base_model %>% save_model_hdf5("base_modelf.h5")
#new_model<-load_model_hdf5("base_model9am.h5")

new_model1<-load_model_hdf5("base_modele.h5")
new_model2<-load_model_hdf5("base_modelb.h5")
preds1<-predict(new_model1,batch_size = 64, x=xtest)
preds2<-predict(new_model2,batch_size = 64, x=xtest)
prediction_matrix1<-table(preds1,ytest)%>%as.data.frame
prediction_matrix2<-table(preds2,ytest)%>%as.data.frame

prediction(preds1,ytest)%>%
  performance(measure="tpr",x.measure="fpr")%>%plot()
prediction(preds2,ytest)%>%
  performance(measure="tpr",x.measure="fpr")%>%plot()
base_density1<-prediction_matrix1%>%
  uncount(Freq)%>%
  mutate(preds=as.numeric(paste0(preds1)))%>%
  ggplot(aes(x=preds,colour=ytest,fill=ytest))+
  geom_density(alpha=.5)
base_density2<-prediction_matrix2%>%
  uncount(Freq)%>%
  mutate(preds=as.numeric(paste0(preds2)))%>%
  ggplot(aes(x=preds,colour=ytest,fill=ytest))+
  geom_density(alpha=.5)

base_density
base_density1
base_density2
table(ifelse(as.numeric(paste0(preds1))>.075,1,0),
      ytest)
base_density
```


```{r early_stopping_model}
#recreate a base model 
base_model=keras_model_sequential()
l1=1e-2

base_model%>%
  layer_dense(units=32,activation="relu",kernel_regularizer=regularizer_l1(l1),
              input_shape=ncol(xtrain))%>%
  #layer_dense(units=32,activation="relu",kernel_regularizer=regularizer_l1(l1))%>%
  #layer_dense(units=32,activation="tanh",kernel_regularizer=regularizer_l1(l1))%>%

  layer_dense(units=32,activation="relu",kernel_regularizer=regularizer_l1(l1))%>%
  layer_dense(units=1,activation="sigmoid",kernel_regularizer=regularizer_l1(l1))
summary(base_model)

#compile base model, binary_crossentropy is appropriate for classification task
base_model%>%compile(
  loss='binary_crossentropy',
  optimizer=optimizer_adam(),
  metrics=c('mae')
)


### Train model
inner_epochs = 50
early_stopping = callback_early_stopping(monitor = "val_loss",
                                         patience = inner_epochs/5)
bestLoss = 100
for(i in 1:20) {
  history = base_model %>% fit(xtrain,ytrain,
                       epochs=inner_epochs,
                       callbacks = c(early_stopping),
                       batch_size=64,
                       validation_split=0.2,
                       #define class_weights to account for rarity of school closures
                       class_weights=c("0"=1,"1"=23),
                       shuffle=T)
  
  loss = history$metrics$val_loss[length(history$metrics$val_loss)]
  if(loss < bestLoss) {
    bestLoss = loss
    base_model %>% save_model_weights_hdf5("early_stopping/my_model_weights2.h5")
  }
}
loss
### Plot performance 
plot(history, metrics = "loss")  # only plots the last part of training

### Load the early-stopping model
bestModel = base_model %>% load_model_weights_hdf5('early_stopping/my_model_weights.h5')
bestModel %>% compile(
  # loss = 'categorical_crossentropy',
  loss = 'mae',
  optimizer = optimizer_nadam(),
  metrics = c('mae')
)


preds<-predict(bestModel,batch_size = 64, x=xtest)

prediction_matrix<-table(preds,ytest)%>%as.data.frame
ft_auc=prediction(preds,ytest)%>%
  performance("auc")%>%.@y.values%>%.[[1]]

prediction(preds,ytest)%>%
  performance(measure="tpr",x.measure="fpr")%>%plot()

base_density<-prediction_matrix%>%
  uncount(Freq)%>%
  mutate(preds=as.numeric(paste0(preds)))%>%
  ggplot(aes(x=preds,colour=ytest,fill=ytest))+
  geom_density(alpha=.5)
base_density
base_density2

#evaluate best early_stopping model against model e from previous chunk
mod1<-base_model %>% load_model_weights_hdf5('early_stopping/my_model_weights.h5')
rm(mod2)
mod2<-load_model_hdf5('base_modele.h5')



#generate predictions for each
preds1<-predict(mod1,batch_size = 64, x=xtest)
preds2<-predict(mod2,batch_size = 64, x=xtest)

prediction_matrix1<-table(preds1,ytest)%>%as.data.frame
prediction_matrix2<-table(preds2,ytest)%>%as.data.frame

base_density1<-prediction_matrix1%>%
  uncount(Freq)%>%
  mutate(preds=as.numeric(paste0(preds1)))%>%
  ggplot(aes(x=preds,colour=ytest,fill=ytest))+
  geom_density(alpha=.5)

base_density2<-prediction_matrix2%>%
  uncount(Freq)%>%
  mutate(preds=as.numeric(paste0(preds2)))%>%
  ggplot(aes(x=preds,colour=ytest,fill=ytest))+
  geom_density(alpha=.5)

base_density1
base_density2

evaluate1<-prediction(preds1,ytest)
evaluate2<-prediction(preds2,ytest)

RP.perf1 <- performance(evaluate1, "prec", "rec")
RP.perf2 <- performance(evaluate2, "prec", "rec")

f1_1<-performance(evaluate1,"f")
f1_2<-performance(evaluate2,"f")

for_plot<-data.frame(Recall= RP.perf1@x.values%>%unlist,
                     Precision= RP.perf1@y.values%>%unlist,
                     Mod="Mod1")%>%
  rbind(data.frame(Recall= RP.perf2@x.values%>%unlist,
                     Precision= RP.perf2@y.values%>%unlist,
                     Mod="Mod2"))

for_plot%>%
  ggplot(aes(x=Recall,y=Precision,color=Mod))+geom_line()



```
`The original model (non-early stopping trained) outperforms the early-stopping trained model at higher levels of recall.`

```{r fine_tune}
# predictions<-base_model$output%>%
#   layer_dense(units=1024,activation='relu',kernel_regularizer = regularizer_l1())%>%
#   layer_dense(units=1,activation='sigmoid',kernel_regularizer=regularizer_l1())
# 
# #create fine tune model
# ft=keras_model(inputs=base_model$input,outputs=predictions)
# freeze_weights(base_model)
# 
# ft%>%compile(optimizer='adam',loss = 'binary_crossentropy')
# 
# history1<-ft%>%fit(x=xtrain,
#                    y=ytrain,
#                    epochs=100,
#                    batch_size=8,
#                    validation_split=.1,
#                    class_weights=c("0"=1,"1"=23))
# #freeze first 4 base_model weights
# freeze_weights(base_model,from=1,to=2)
# 
# unfreeze_weights(base_model,from=3)
# ft%>%compile(optimizer=optimizer_sgd(lr=0.0001,momentum=0.9),
#              loss='binary_crossentropy')
# history2<-ft%>%fit(x=xtrain,y=ytrain,epochs=10,batch_size=8)

```

```{r test_fine_tuned}
# preds<-predict(ft,batch_size = 64, x=xtest)
# 
# prediction_matrix<-table(preds,ytest)%>%as.data.frame
# ft_auc=prediction(preds,ytest)%>%
#   performance("auc")%>%.@y.values%>%.[[1]]
# 
# prediction(preds,ytest)%>%
#   performance(measure="tpr",x.measure="fpr")%>%plot()
# 
# ft_density<-prediction_matrix%>%
#   uncount(Freq)%>%
#   mutate(preds=as.numeric(paste0(preds)))%>%
#   ggplot(aes(x=preds,colour=ytest,fill=ytest))+
#   geom_density(alpha=.5)
# 
# #create a test confusion matrix
# table(ifelse(as.numeric(paste0(preds))>.15,1,0),
#       ytest)
# base_density
# ft_density
```